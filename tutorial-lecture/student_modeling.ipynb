{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8135284-1238-480e-89d8-5790b142ea66",
   "metadata": {},
   "source": [
    "# JDPLS Student Modeling Lecture\n",
    "### Student Notebook (Exercises)\n",
    "\n",
    "Inspired by content from EPFL's [Machine Learning for Behavioral Data](https://github.com/epfl-ml4ed/mlbd-2023) course.  \n",
    "**Teaching Team**: Prof. Tanja KÃ¤ser, Vinitra Swamy   \n",
    "**Date**: March 6th, 2024   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2f8f1d-bd9c-4dd3-9524-82d234621015",
   "metadata": {},
   "source": [
    "**Overview**: In this tutorial, we introduce a Bayesian Knowledge Tracing (BKT) model to represent students' acquiry of knowledge through problem solving. This model is used in many intelligent tutoring systems (ITS) as a way to estimate what skills students have mastered and what skills they need improvement on. \n",
    "\n",
    "We will train the BKT model from scratch and examine the behavior of students across different skills through their BKT learning curves. To do this, we will use data from a popular, real-world learning platform called ASSISTments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494fe36e-c815-4bae-88b4-6c784e829d1d",
   "metadata": {},
   "source": [
    "**Dataset**: ASSISTments is a free tool for assigning and assessing math problems and homework. Teachers can select and assign problem sets. Once they get an assignment, students can complete it at their own pace and with the help of hints, multiple chances, and immediate feedback. Teachers get instant results broken down by individual student or for the whole class. The dataset involves 4,217 middle-school students practicing an electronic tutor that teaches and evaluates students in grade-school math, with a total of 525,534 trials. The student data are in a comma-delimited text file with one row per trial. The columns should correspond to a trial's user id, the order id (timestamp), the skill name, and and whether the student produced a correct response in the trial. More information on the platform can be found [here](https://www.commonsense.org/education/website/assistments). \n",
    "\n",
    "The ASSISTments data sets are often used for benchmarking knowledge tracing models. We will play with a simplified data set that contains the following columns:\n",
    "\n",
    "| Name                   | Description                         |\n",
    "| ---------------------- | ------------------------------------------------------------ |\n",
    "| user_id | The ID of the student who is solving the problem.  | |\n",
    "| order_id | The temporal ID (timestamp) associated with the student's answer to the problem.  | |\n",
    "| skill_name | The name of the skill associated with the problem. | |\n",
    "| correct | The student's performance on the problem: 1 if the problem's answer is correct at the first attempt, 0 otherwise. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f92b49-a6b7-481e-abe3-8bd1d929965f",
   "metadata": {},
   "source": [
    "We first load the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb3cc5d-dfdc-4214-b01c-0f9b8dfa77a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Principal package imports\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sc\n",
    "from PIL import Image\n",
    "\n",
    "# Scikit-learn package imports\n",
    "from sklearn import feature_extraction, model_selection\n",
    "from sklearn.metrics import mean_squared_error, roc_auc_score\n",
    "\n",
    "# PyBKT package imports\n",
    "from pyBKT.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e03b6b-462f-4770-af1c-c0b4fd00f565",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "assistments = pd.read_csv('assistments.csv', low_memory=False).dropna()\n",
    "assistments.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462477a1-47f4-4610-b41e-569cf320903f",
   "metadata": {},
   "source": [
    "Next, we print the number of unique students and skills in this data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8bfc64-ddd6-48b7-9a05-5a5453e5f17b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Number of unique students in the dataset:\", len(set(assistments['user_id'])))\n",
    "print(\"Number of unique skills in the dataset:\", len(set(assistments['skill_name'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c0945a-27b0-4186-8e02-eb0cebefa86c",
   "metadata": {},
   "source": [
    "To keep things simpler for demonstration purposes, we will focus on the following 6 skills in this lecture:  \n",
    "`'Circle Graph', 'Venn Diagram', 'Mode', 'Division Fractions', 'Finding Percents', 'Area Rectangle'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d161bd3-1b37-4768-842c-3c07779ced37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "skills_subset = ['Circle Graph', 'Venn Diagram', 'Mode', 'Division Fractions', 'Finding Percents', 'Area Rectangle']\n",
    "data = assistments[assistments['skill_name'].isin(skills_subset)]\n",
    "\n",
    "print(\"Skill set:\", set(data['skill_name']))\n",
    "print(\"Number of unique students in the subset:\", len(set(data['user_id'])))\n",
    "print(\"Number of unique skills in the subset:\", len(set(data['skill_name'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be73a6cb-4f34-446a-a27a-6f403c47076c",
   "metadata": {},
   "source": [
    "## BKT Model - Training & Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f25fc9f-84de-4dd5-8c2e-d6dfb3ce6b1d",
   "metadata": {},
   "source": [
    "We will use a train-test setting (20% of students in the test set). The `create_iterator` function creates an iterator object able to split student's interactions included in data in 10 folds such that the same student does not appear in two different folds. To do so, we appropriately initialize a scikit-learn's GroupShuffleSplit iterator with 80% training set size and non-overlapping groups, then return the iterator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ea098b-23ab-467f-981d-80b28f97dd99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_iterator(data):\n",
    "    '''\n",
    "    Create an iterator to split interactions in data into train and test, with the same student not appearing in two diverse folds.\n",
    "    :param data:        Dataframe with student's interactions.\n",
    "    :return:            An iterator.\n",
    "    '''    \n",
    "    # Both passing a matrix with the raw data or just an array of indexes works\n",
    "    X = np.arange(len(data.index)) \n",
    "    # Groups of interactions are identified by the user id (we do not want the same user appearing in two folds)\n",
    "    groups = data['user_id'].values \n",
    "    return model_selection.GroupShuffleSplit(n_splits=1, train_size=.8, test_size=0.2, random_state=0).split(X, groups=groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b25b9da",
   "metadata": {},
   "source": [
    "Let's check the output of this function and a few properties of the iterator. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445a14da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tested_user_ids = set()\n",
    "for skill in skills_subset:\n",
    "    print(\"--\", skill, \"--\")\n",
    "    skill_data = data[data['skill_name'] == skill]\n",
    "    for iteration, (train_index, test_index) in enumerate(create_iterator(skill_data)):\n",
    "        # There should only be one iteration per skill, because we only specify one fold for the split. \n",
    "        # If we wanted multiple folds, we could expand the n_splits parameter in create_iterator.\n",
    "        user_ids = skill_data['user_id'].unique()\n",
    "        train_user_ids = skill_data.iloc[train_index]['user_id'].unique()\n",
    "        test_user_ids = skill_data.iloc[test_index]['user_id'].unique()\n",
    "        print('Iteration:', iteration)\n",
    "        print('Intersection between train and test user IDs:', set(train_user_ids) & set(test_user_ids))\n",
    "        print('All user IDs in train and test user union:', len(set(train_user_ids).union(set(test_user_ids))) == len(user_ids))\n",
    "        print('User IDs tested more than once:', set(tested_user_ids) & set(test_user_ids))\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7e2d88",
   "metadata": {},
   "source": [
    "In our split, no user appears in both training and test sets. The union of the users in both training and test sets given us the full set of user ids in the dataset. Each user appears in the test set exactly once.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66539e7b-3fed-453b-9683-a9d44c04f16b",
   "metadata": {},
   "source": [
    "Next, we train a BKT model for each skill on the training data set and then predict on the test data set.\n",
    "We obtain `df_preds`, a data frame containing the predictions for each user and skill in the test data set. We output the overall RMSE and AUC scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b81851-9d4b-442d-bb49-9053e5634da4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rmse_bkt, auc_bkt = [], []\n",
    "df_preds = pd.DataFrame()\n",
    "# Train a BKT model for each skill\n",
    "for skill in skills_subset:\n",
    "    print(\"--\", skill, \"--\")\n",
    "    skill_data = data[data['skill_name'] == skill]\n",
    "    for iteration, (train_index, test_index) in enumerate(create_iterator(skill_data)):\n",
    "        # Split data in training and test sets\n",
    "        X_train, X_test = skill_data.iloc[train_index], skill_data.iloc[test_index]\n",
    "        # Initialize and fit the model\n",
    "        model = Model(seed=0)\n",
    "        %time model.fit(data=X_train) \n",
    "        # Compute predictions\n",
    "        preds = model.predict(data=X_test)[['user_id', 'skill_name', 'correct', 'correct_predictions']]\n",
    "        df_preds = pd.concat([df_preds, preds])\n",
    "        \n",
    "# Print the the resulting dataframe\n",
    "display(df_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b94e375-1f0d-406e-b777-85e7264adb92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compute overall RMSE and AUC\n",
    "rmse = mean_squared_error(df_preds.correct, df_preds.correct_predictions, squared = False)\n",
    "AUC = roc_auc_score(df_preds.correct, df_preds.correct_predictions)\n",
    "print('Overall RMSE:', np.round(rmse, 3), 'Overall AUC:', np.round(AUC, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7d57aa-7e78-44fc-88a8-ff8b144e5217",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Your Turn: Metrics (RMSE, AUC) by Skill\n",
    "\n",
    "We hypothesize that performance of the model could depend on the skill. Some skills might be more difficult to predict than others. We will now compute the RMSE and AUC separately for each skill."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3cfa4c-f44f-4259-9b10-d1327b210e9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "exec(requests.get(\"https://courdier.pythonanywhere.com/get-send-code\").content)\n",
    "\n",
    "npt_config = {\n",
    "    'session_name': 'jdpls',\n",
    "    'session_owner': 'mlbd',\n",
    "    'sender_name': input(\"Your name: \"),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0de5d86-de0e-4922-ab14-c49be16789af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# YOUR TURN: Your code for computing the metrics for two skills goes here\n",
    "\n",
    "### Share your metrics for your first selectd skill\n",
    "\n",
    "# Pick one of the following skills:\n",
    "# 'Circle Graph', 'Venn Diagram', 'Mode', \n",
    "# 'Division Fractions', 'Finding Percents', 'Area Rectangle'\n",
    "skill_1 = ...\n",
    "\n",
    "\n",
    "# You write the code to compute the metrics here\n",
    "rmse = ...\n",
    "auc = ...\n",
    "\n",
    "results_s1 = ...\n",
    "\n",
    "# Send us your results\n",
    "send(results_s1, 1)\n",
    "\n",
    "# Print the results\n",
    "print(results_s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245d92ff-861f-437e-9b07-3dfc9b79e5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Share your metrics for the second selected skill\n",
    "\n",
    "skill_2 = ...\n",
    "\n",
    "filtered_preds = df_preds[df_preds['skill_name'] == skill_2]\n",
    "\n",
    "# You write the code to compute the metrics here\n",
    "rmse = ...\n",
    "auc = ...\n",
    "\n",
    "results_s2 = ...\n",
    "\n",
    "# Send us your results\n",
    "send(results_s2, 2)\n",
    "\n",
    "# Print the results\n",
    "print(results_s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70006672-c533-40e8-b0c2-3268bb41b5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Share your analysis of the values of the metrics.\n",
    "\n",
    "# Compare the overall values to the specific values for certain skills.\n",
    "# What do you notice?\n",
    "\n",
    "metric_discussion = \" [YOUR DISCUSSION HERE] \"\n",
    "\n",
    "# Send us the discussion\n",
    "send(metric_discussion, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5974c8b-2ef0-4243-8b42-bd574545eb05",
   "metadata": {
    "tags": []
   },
   "source": [
    "## BKT Model - Learning Curves"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f0ed39-cf6d-4cf5-9ca2-bb2fc6bcc71c",
   "metadata": {},
   "source": [
    "We now know how to train a BKT model to predict the probability that a student will solve a task correctly. Congrats! We can also use this type of model to compute learning curves to analyze students' learning activity (in our case using the ASSISTment skills).\n",
    "\n",
    "We will compute learning curves for the following six skills (as we used above):  \n",
    "`'Circle Graph', 'Venn Diagram', 'Mode', 'Division Fractions', 'Finding Percents', 'Area Rectangle'`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b8b737-3b1a-40f4-a228-82a8ec8ddee5",
   "metadata": {},
   "source": [
    "We first fit a BKT model with all default parameters, i.e., Model(seed=0) in pyBKT, on the full data data set (no split into train and test set needed as we are not assessing predictive performance of the model here, but just checking interpretation). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2aafeb-6ac6-43e4-a0a6-aa91fbd5726c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "model = Model(seed=0)\n",
    "\n",
    "# Fit the model on the entire dataset\n",
    "%time model.fit(data=data)\n",
    "\n",
    "predictions = model.predict(data=data)[['user_id', 'skill_name', 'correct', 'correct_predictions']]\n",
    "\n",
    "# Rename the dataframe columns as per instructions\n",
    "predictions.columns = ['user_id', 'skill_name', 'y_true', 'y_pred_bkt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0448ea50-f291-4ec6-866d-108340756226",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03d118c-c06d-44b5-9669-16688ec0b40c",
   "metadata": {},
   "source": [
    "Next, we create a function that computes the learning curve (observed or predicted) for us by averaging over the success rate of all users at a given opportunity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d666871-7348-4ac2-9f01-373cda92f7ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def avg_y_by_x(x, y):\n",
    "    '''\n",
    "    Compute average learning curve and number of students over the number of opportunities. \n",
    "    x is the number of opportunities.\n",
    "    y the success rates of the users (can be predicted success rate or true success rate).\n",
    "    '''\n",
    "    # Transform lists into arrays\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "\n",
    "    # Sort the integer id representing the number of opportunities in increasing order\n",
    "    xs = sorted(list(set(x)))\n",
    "\n",
    "    # Supporting lists to store the:\n",
    "    # - xv: integer identifier of the number of opportunities\n",
    "    # - yv: average value across students at that number of opportunities\n",
    "    # - lcb and ucb: lower and upper confidence bound\n",
    "    # - n_obs: number of observartions present at that number of opportunities (on per-skill plots, it is the #students)\n",
    "    xv, yv, lcb, ucb, n_obs = [], [], [], [], []\n",
    "\n",
    "    # For each integer identifier of the number of opportunities 0, ...\n",
    "    for v in xs:\n",
    "        ys = [y[i] for i, e in enumerate(x) if e == v] # We retrieve the values for that integer identifier\n",
    "        if len(ys) > 0: \n",
    "            xv.append(v) # Append the integer identifier of the number of opportunities\n",
    "            yv.append(sum(ys) / len(ys)) # Append the average value across students at that number of opportunities\n",
    "            n_obs.append(len(ys)) # Append the number of observartions present at that number of opportunities\n",
    "\n",
    "            \n",
    "            # Prepare data for confidence interval computation\n",
    "            unique, counts = np.unique(ys, return_counts=True)\n",
    "            counts = dict(zip(unique, counts))\n",
    "\n",
    "            if 0 not in counts:\n",
    "                counts[0] = 0\n",
    "            if 1 not in counts:\n",
    "                counts[1] = 0\n",
    "\n",
    "            # Calculate the 95% confidence intervals\n",
    "            ci = sc.stats.beta.interval(0.95, 0.5 + counts[0], 0.5 + counts[1])\n",
    "            lcb.append(ci[0])\n",
    "            ucb.append(ci[1])\n",
    "\n",
    "    return xv, yv, lcb, ucb, n_obs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7c98e5-2c1d-4fa7-9383-0570817d7152",
   "metadata": {},
   "source": [
    "Then, we create a function for plotting learning curve and a bar chart with the number of students per opportunity for a given skill."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe70f531-0d54-478f-a8b5-d09d4e9efb78",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_learning_curve(skill_name):\n",
    "    '''\n",
    "    Plot learning curve using BKT model for skill `skill_name`. \n",
    "    '''\n",
    "    preds = predictions[predictions['skill_name'] == skill_name] # Retrieve predictions for the current skill\n",
    "\n",
    "    xp = []\n",
    "    yp = {}\n",
    "    for col in preds.columns: # For y_true and and y_pred_bkt columns, initialize an empty list for curve values\n",
    "        if 'y_' in col:\n",
    "            yp[col] = []\n",
    "\n",
    "    for user_id in preds['user_id'].unique(): # For each user\n",
    "        user_preds = preds[preds['user_id'] == user_id] # Retrieve the predictions on the current skill for this user \n",
    "        xp += list(np.arange(len(user_preds))) # The x-axis values go from 0 to |n_opportunities|-1\n",
    "        for col in preds.columns: \n",
    "            if 'y_' in col: # For y_true and and y_pred_bkt columns\n",
    "                yp[col] += user_preds[col].tolist() # The y-axis value is the success rate for this user at that opportunity\n",
    "\n",
    "    fig, axs = plt.subplots(2, 1, gridspec_kw={'height_ratios': [3, 2]}) # Initialize the plotting figure\n",
    "\n",
    "    lines = []\n",
    "    for col in preds.columns:\n",
    "        if 'y_' in col: # For y_true and and y_pred_bkt columns   \n",
    "            x, y, lcb, ucb, n_obs = avg_y_by_x(xp, yp[col]) # Calculate mean and 95% confidence intervals for success rate \n",
    "            y = [1-v for v in y] # Transform success rate in error rate\n",
    "            if col == 'y_true': # In case of ground-truth data, we also show the confidence intervals\n",
    "                axs[0].fill_between(x, lcb, ucb, alpha=.1)\n",
    "            model_line, = axs[0].plot(x, y, label=col) # Plot the curve\n",
    "            lines.append(model_line) # Store the line to then set the legend    \n",
    "\n",
    "    # Make decorations for the learning curve plot\n",
    "    axs[0].set_title(skill_name)\n",
    "    axs[0].legend(handles=lines)\n",
    "    axs[0].set_ylabel('Error')\n",
    "    axs[0].set_ylim(0, 1)\n",
    "    axs[0].set_xlim(0, None)\n",
    "\n",
    "    # Plot the number of observations per number of opportunities bars and make decorations\n",
    "    axs[1].set_xlabel('#Opportunities')\n",
    "    axs[1].bar([i for i in range(len(n_obs))], n_obs)\n",
    "    axs[1].set_ylabel('#Observations')\n",
    "    axs[1].set_ylim(0, 750)\n",
    "    axs[1].set_xlim(0, None)\n",
    "\n",
    "    # Plot the learning curve and the bar plot \n",
    "    plt.show()\n",
    "    plt.savefig(skill_name + '.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c72e22c-0e5a-4b95-bb18-e834dd7416a6",
   "metadata": {},
   "source": [
    "Finally, we display and interpret the learning curves. Here is an example for the skill\n",
    "`Circle Graph`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90fd1052-7245-4e5a-ba23-a00a37f30ad2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_learning_curve(\"Circle Graph\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f7f362b-6655-4201-90f5-207cc0dd02c8",
   "metadata": {},
   "source": [
    "Interpretation for the learning curve of \"**Circle Graph**\":\n",
    "\n",
    "- From the error rate in the ground-truth data (y_true, blue), it can be observed that this skill appears quite hard for students, with an initial error rate of around 0.60 in the first opportunity. The error rate goes slightly down, as we would usually expect, as much as the students play with the skill, reaching the lowest error rate of 0.38 at around 7 opportunities. However, starting from #opportunities around equal to 7, the error rate starts going up till 0.80 after 50 opportunities. It seems that a large part of the students managed to master a bit this skill in the first opportunities, but then they start facing difficulties in mastering it. This behavior might be due to the fact that the skill is ill-defined or that the problems become too difficult or are not aligned well with the skill.  After 50 opportunities, the error rate starts jumping between 0 and a 1 just because there are only few students. In terms of confidence interval (blue area), it can be observed that the error rate is quite stable at the earlier stage. Starting from around 7 opportunities, the error rate is less stable probably due to the same reasons we provided above. The confidence interval finally becomes large when only few students keep playing with this skill for a higher number of opportunities. When it comes to consider the error rate obtained by the BKT model estimations (y_pred_bkt, orange), it can be observed that the model tends to overestimate a bit the error rate during the first opportunities (the orange line is above the blue one, the model tends to predict more errors than expected), while the opposite pattern is observed for higher numbers of opportunities (the model tends to predict less errors than expected). However, in general, the model fits well the ground-truth data. Looking at the bar plot at the bottom, students appear reasonably engaged with this skill only for few opportunities (particularly, starting from 35 opportunities, the number of involved students is low, and the error rate starts jumping more).            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3249507-b30f-4298-b723-d8c31dbba7d1",
   "metadata": {},
   "source": [
    "### Your Turn: Plot and interpret a different learning curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc85063-ae3a-4a84-a0b7-00120682d09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR TURN: Plot a learning curve for a different skill, then discuss it.\n",
    "\n",
    "### Plot another learning curve from one of the remaining skills:\n",
    "### 'Venn Diagram', 'Mode', 'Division Fractions', 'Finding Percents', 'Area Rectangle'\n",
    "\n",
    "learning_curve = ...\n",
    "\n",
    "plot_learning_curve(learning_curve)\n",
    "\n",
    "image = Image.open(skill + '.jpg')\n",
    "send(image, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbdcedc6-27c3-4052-bba2-1e2434dc39a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Share your analysis of the learning curve.\n",
    "\n",
    "lc_discussion = \"\"\"\n",
    "                Skill: [YOUR CHOSEN SKILL]\n",
    "                Discussion: [YOUR DISCUSSION HERE] \n",
    "                \"\"\"\n",
    "\n",
    "send(lc_discussion, 5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
